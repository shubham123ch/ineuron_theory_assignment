{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Shubham Kumar Chaturvedi(ComputerVision assigment no: 4)"
      ],
      "metadata": {
        "id": "06CYJfvUOrPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: What is the concept of cyclical momentum?\n",
        "\n",
        "ANS:The swing is cycling between forward and backward arcs. If you want to make it go higher, you give it a push when the momentum of the cycle is in your favorâ€”that is, the kid is moving forward.\n",
        "\n",
        "Q2: What callback keeps track of hyperparameter values (along with other data) during\n",
        "training?\n",
        "\n",
        "ANS: The save_hyperparameters() method will save all the hyperparameters that are present in the object into a YAML file.\n",
        "\n",
        "Q3: In the color dim plot, what does one column of pixels represent?\n",
        "\n",
        "ANS:  a pixel can be identified by a pair of integers giving the column number and the row number. For example, the pixel with coordinates (3,5) would lie in column number 3 and row number 5. Conventionally, columns are numbered from left to right, starting with zero.\n",
        "\n",
        "Q4:  In color dim, what does &quot;poor teaching&quot; look like? What is the reason for this?\n",
        "\n",
        "ANS: Colour helps us in memorizing certain information by increasing our attentional level.\n",
        "\n",
        "Q5: Does a batch normalization layer have any trainable parameters?In batch normalization during preparation, what statistics are used to normalize? \n",
        "\n",
        "ANS: training=False : The layer will normalize its inputs using the mean and variance of its moving statistics, learned during training.\n",
        "\n",
        "Q7:Why do batch normalization layers help models generalize better?\n",
        "\n",
        "ANS:  it is a process to make neural networks faster and more stable through adding extra layers in a deep neural network. The new layer performs the standardizing and normalizing operations on the input of a layer coming from a previous layer.\n",
        "\n",
        "Q8:Explain between MAX POOLING and AVERAGE POOLING is number eight.\n",
        "\n",
        "ANS: Average pooling computes the average of the elements present in the region of feature map covered by the filter. Thus, while max pooling gives the most prominent feature in a particular patch of the feature map, average pooling gives the average of features present in a patch.\n",
        "\n",
        "Q9:What is the purpose of the POOLING LAYER?\n",
        "\n",
        "ANS: Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer.\n",
        "\n",
        "Q10: Why do we end up with Completely CONNECTED LAYERS?\n",
        "\n",
        "ANS: A fully connected layer refers to a neural network in which each neuron applies a linear transformation to the input vector through a weights matrix. As a result, all possible connections layer-to-layer are present, meaning every input of the input vector influences every output of the output vector.\n",
        "\n",
        "Q11: What do you mean by PARAMETERS?\n",
        "\n",
        "ANS: A model parameter is a configuration variable that is internal to the model and whose value can be estimated from the given data. They are required by the model when making predictions. Their values define the skill of the model on your problem.\n",
        "\n",
        "Q12: What formulas are used to measure these PARAMETERS?\n",
        "\n",
        "ANS: Number of parameters in a CONV layer would be : ((m * n * d)+1)* k), added 1 because of the bias term for each filter. The same expression can be written as follows: ((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)."
      ],
      "metadata": {
        "id": "KewVUCcjOwtq"
      }
    }
  ]
}