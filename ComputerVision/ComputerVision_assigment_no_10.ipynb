{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Shubham Kumar Chaturvedi(ComputerVision assigment no: 10)"
      ],
      "metadata": {
        "id": "q77w7YpuU4CH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: Why don&#39;t we start all of the weights with zeros?\n",
        "\n",
        "ANS: Initializing all the weights with zeros leads the neurons to learn the same features during training. In fact, any constant initialization scheme will perform very poorly.\n",
        "\n",
        "Q2: Why is it beneficial to start weights with a mean zero distribution?\n",
        "\n",
        "ANS: A neural network works best when input data is centered (have a mean of 0 and std of 1). So when input values get multiplied by weight value.\n",
        "\n",
        "Q3: What is dilated convolution, and how does it work?\n",
        "\n",
        "ANS: Dilated Convolution: It is a technique that expands the kernel (input) by inserting holes between its consecutive elements. In simpler terms, it is the same as convolution but it involves pixel skipping, so as to cover a larger area of the input.\n",
        "\n",
        "Q4: What is TRANSPOSED CONVOLUTION, and how does it work?\n",
        "\n",
        "ANS: Transposed convolutions are standard convolutions but with a modified input feature map. The stride and padding do not correspond to the number of zeros added around the image and the amount of shift in the kernel when sliding it across the input, as they would in a standard convolution operation.\n",
        "\n",
        "Q5: Explain Separable convolution\n",
        "\n",
        "ANS: A Separable Convolution is a process in which a single convolution can be divided into two or more convolutions to produce the same output. A single process is divided into two or more sub-processes to achieve the same effect.\n",
        "\n",
        "Q6: What is depthwise convolution, and how does it work?\n",
        "\n",
        "ANS: Depthwise Convolution is a type of convolution where we apply a single convolutional filter for each input channel. In the regular 2D convolution performed over multiple input channels, the filter is as deep as the input and lets us freely mix channels to generate each element in the output.\n",
        "\n",
        "Q7: What is Depthwise separable convolution, and how does it work?\n",
        "\n",
        "ANS: The depthwise separable convolution is so named because it deals not just with the spatial dimensions, but with the depth dimension — the number of channels — as well. An input image may have 3 channels: RGB. After a few convolutions, an image may have multiple channels.\n",
        "\n",
        "Q8:Capsule networks are what they sound like.\n",
        "\n",
        "ANS: Capsule Networks (CapsNet) are the networks that are able to fetch spatial information and more important features so as to overcome the loss of information that is seen in pooling operations.there is no spatial information that is used anywhere in a CNN and the pooling function that is used to connect layers, is really really inefficient. \n",
        "\n",
        "Q9:Why is POOLING such an important operation in CNNs?\n",
        "\n",
        "ANS: Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer.\n",
        "\n",
        "Q10:What are receptive fields and how do they work?\n",
        "\n",
        "ANS: The receptive field encompasses the sensory receptors that feed into sensory neurons and thus includes specific receptors on a neuron as well as collectives of receptors that are capable of activating a neuron via synaptic connections.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "haUGawkeU9M3"
      }
    }
  ]
}