{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUVOFNCG2EN6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shubham Kumar Chaturvedi(DeepLearning assigment no: 5)"
      ],
      "metadata": {
        "id": "9hljlr7g2FOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: Why would you want to use the Data API?\n",
        "\n",
        "ANS: APIs are needed to bring applications together in order to perform a designed function built around sharing data and executing pre-defined processes. They work as the middle man, allowing developers to build new programmatic interactions between the various applications people and businesses use on a daily basis.\n",
        "\n",
        "Q2: What are the benefits of splitting a large dataset into multiple files?\n",
        "\n",
        "ANS: By splitting your databases, you can make them more secure, if all your database designs are stored in the backend, no one from the front end will be able to make any kind of changes in the tables. And those accessing the backend will not be able to view the interface objects.\n",
        "\n",
        "Q3: During training, how can you tell that your input pipeline is the bottleneck? What can you do\n",
        "to fix it?\n",
        "\n",
        "ANS: Using TensorBoard you can see if the GPU is not fully utilized, which is likely to bottleneck.\n",
        "we can fix by making sure it reads and preprocesses the data in multiple threads in parallel, and prefetches a few batches.\n",
        "\n",
        "Q4: Can you save any binary data to a TFRecord file, or only serialized protocol buffers?\n",
        "\n",
        "ANS: A TFRecord is a binary file that contains sequences of byte-strings. Data needs to be serialized (encoded as a byte-string) before being written into a TFRecord.\n",
        "\n",
        "Q5: Why would you go through the hassle of converting all your data to the Example protobuf\n",
        "format? Why not use your own protobuf definition?\n",
        "\n",
        "ANS: Unlike other formats, nested Protobuf messages cannot be written contiguously into a stream without significant buffering. The post doesn't argue to never use Protobuf, but that the trade-off made by the wire-format itself, as opposed to any existing implementation, is unlikely to work for lightweight message senders.\n",
        "\n",
        "Q7: Data can be preprocessed directly when writing the data files, or within the tf.data pipeline,\n",
        "or in preprocessing layers within your model, or using TF Transform. Can you list a few pros\n",
        "and cons of each option?\n",
        "\n",
        "ANS:  Create an input function for training.\n",
        "\n",
        "Train, Evaluate the model.\n",
        "Transform new data.\n",
        "Export the model."
      ],
      "metadata": {
        "id": "8o9vaDbk2Ngx"
      }
    }
  ]
}