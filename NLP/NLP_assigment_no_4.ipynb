{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Shubham Kumar Chaturvedi(NLP assigment no: 4)"
      ],
      "metadata": {
        "id": "u8_wLLajdGh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: Can you think of a few applications for a sequence-to-sequence RNN? What about a\n",
        "sequence-to-vector RNN? And a vector-to-sequence RNN?\n",
        "\n",
        "ANS: In Sequence to Sequence Learning, RNN is trained to map an input sequence to an output sequence which is not necessarily of the same length. Applications are speech recognition, machine translation, image captioning and question answering.\n",
        "Applications of Recurrent Neural Networks:\n",
        "Prediction problems.\n",
        "Machine Translation.\n",
        "Speech Recognition.\n",
        "Language Modelling and Generating Text.\n",
        "Video Tagging.\n",
        "Generating Image Descriptions.\n",
        "Text Summarization.\n",
        "Call Center Analysis.\n",
        "\n",
        "Sometimes both the input and output are sequences, in some either the input or the output is a sequence. Recurrent neural network (RNN) is a popular sequence model that has shown efficient performance for sequential data.\n",
        "\n",
        "The RNN model takes a single vector as input and produces a sequence as output. An example of these models can be image to sentence model, which takes an image(consider it as a vector) and then produces a sentence to describe that image.\n",
        "\n",
        "Feed sequence of inputs and take only last output, so it is called Sequence-to-Vector. For example, take an IMDB review of a movie and ignore all outputs in the middle to predict the movie horror or drama. Feed the same input vector multiple times at each time and produce an output, so it is called Vector-to-Sequence.\n",
        "\n",
        "\n",
        "Q2: Why do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs\n",
        "for automatic translation?\n",
        "\n",
        "ANS: This two-step model, called an Encoderâ€“Decoder, works much better than trying to translate on the fly with a single sequence-to-sequence RNN (like the one represented on the top left), since the last words of a sentence can affect the first words of the translation, so you need to wait until you have heard the whole sentence.\n",
        "\n",
        "RNN Encoder-Decoder, consists of two recurrent neural networks (RNN) that act as an encoder and a decoder pair. The encoder maps a variable-length source sequence to a fixed-length vector, and the decoder maps the vector representation back to a variable-length target sequence.\n",
        "\n",
        "Q3: How could you combine a convolutional neural network with an RNN to classify videos?\n",
        "\n",
        "ANS: Each video is converted into sequential images and passed onto the CNN to extract spatial features. The outputs are then passed into a recurrent sequence learning model (i.e. LSTM) to identify temporal features within the image sequence.\n",
        "\n",
        "CNN is combined with RNN to extract the correlation characteristics of different RNN models while RNNs running along the time steps. This new architecture not only has the depth of RNN in the time dimension, but also has the width of the number of temporal data.\n",
        "\n",
        "Q4: What are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?\n",
        "\n",
        "ANS:  It is based on a while_loop() operation that is able to swap the GPU's memory to the CPU's memory during backpropagation, avoiding out-of-memory errors.\n",
        "\n",
        "Q5: How can you deal with variable-length input sequences? What about variable-length output\n",
        "sequences?\n",
        "\n",
        "ANS: The first and simplest way of handling variable length input is to set a special mask value in the dataset, and pad out the length of each input to the standard length with this mask value set for all additional entries created. Then, create a Masking layer in the model, placed ahead of all downstream layers.\n",
        "\n",
        "Q6:What is a common way to distribute training and execution of a deep RNN across multiple\n",
        "GPUs?\n",
        "\n",
        "ANS: Once multiple GPUs are added to your systems, we need to build parallelism into deep learning processes. There are two main methods to add parallelism—models and data. Model parallelism is a method you can use when your parameters are too large for your memory constraints.\n",
        "\n",
        "Data-level parallelism is an approach to computer processing that aims to increase data throughput by operating on multiple elements of data simultaneously. There are many motivations for data-level parallelism, including: Researching faster computer systems. Multimedia applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "IVVTt4zKdKYr"
      }
    }
  ]
}