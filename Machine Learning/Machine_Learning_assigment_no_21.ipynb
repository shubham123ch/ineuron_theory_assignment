{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouQ5urpoqpKV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shubham Kumar Chaturvedi(Machine_Learning assigment no: 21)"
      ],
      "metadata": {
        "id": "ikmAoiM4qqA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: What is the estimated depth of a Decision Tree trained (unrestricted) on a one million instance\n",
        "training set?\n",
        "\n",
        "ANS:  if the training set contains one million instances, the Decision Tree will have a depth of log2(106) ≈ 20 (actually a bit more since the tree will generally not be perfectly well balanced).\n",
        "\n",
        "Q2: Is the Gini impurity of a node usually lower or higher than that of its parent? Is it always\n",
        "lower/greater, or is it usually lower/greater?\n",
        "\n",
        "ANS: A node's Gini impurity is generally lower than that of its parent as the CART training algorithm cost function splits each of the nodes in a way that minimizes the weighted sum of its children's Gini impurities.\n",
        "\n",
        "Q3: Explain if its a good idea to reduce max depth if a Decision Tree is overfitting the training set?\n",
        "\n",
        "ANS: If a Decision Tree is overfitting the training set, it may be a good idea to decrease max_depth, since this will constrain the model, regularizing it.\n",
        "\n",
        "Q4: Explain if its a good idea to try scaling the input features if a Decision Tree underfits the training\n",
        "set?\n",
        "\n",
        "ANS: If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features? Decision Trees don't care whether or not the training data is scaled or centered; scaling the input features will just be a waste of time.\n",
        "\n",
        "Q5: How much time will it take to train another Decision Tree on a training set of 10 million instances\n",
        "if it takes an hour to train a Decision Tree on a training set with 1 million instances?\n",
        "\n",
        "ANS:  if the training set contains one million instances, the Decision Tree will have a depth of log2(10⁶) ≈ 20 (actually a bit more since the tree will generally not be perfectly well balanced).\n",
        "\n",
        "Q6: Will setting presort=True speed up training if your training set has 100,000 instances?\n",
        "\n",
        "ANS: Presorting the training set speeds up training only if the dataset is smaller than a few thousand instances. If it contains 100,000 instances, setting presort=True will considerably slow down training.\n",
        "\n"
      ],
      "metadata": {
        "id": "5qEh2K0Zrs9R"
      }
    }
  ]
}