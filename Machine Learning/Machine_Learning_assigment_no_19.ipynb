{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Shubham Kumar Chaturvedi(Machine_Learning assigment no: 18)"
      ],
      "metadata": {
        "id": "bdWAgzH4fTIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: Describe how the Market Basket Research makes use of association analysis concepts.\n",
        "\n",
        "ANS: In market basket analysis, association rules are used to predict the likelihood of products being purchased together. Association rules count the frequency of items that occur together, seeking to find associations that occur far more often than expected.\n",
        "\n",
        "Q2: Give an example of the Apriori algorithm for learning association rules.\n",
        "\n",
        "ANS: Apriori Algorithm is one of the algorithm used for transaction data in Association Rule Learning. It allows us to mine the frequent itemset in order to generate association rule between them. Example: list of items purchased by customers, details of website which are frequently visited etc.\n",
        "\n",
        "Q3: 4. In hierarchical clustering, how is the distance between clusters measured? Explain how this metric\n",
        "is used to decide when to end the iteration.\n",
        "\n",
        "ANS: In complete linkage hierarchical clustering, the distance between two clusters is defined as the longest distance between two points in each cluster. For example, the distance between clusters “r” and “s” to the left is equal to the length of the arrow between their two furthest points.\n",
        "\n",
        "Q4: In the k-means algorithm, how do you recompute the cluster centroids?\n",
        "\n",
        "ANS: Step 1: Choose the number of clusters k. \n",
        "\n",
        "Step 2: Select k random points from the data as centroids. \n",
        "\n",
        "Step 3: Assign all the points to the closest cluster centroid. \n",
        "\n",
        "Step 4: Recompute the centroids of newly formed clusters. \n",
        "\n",
        "Step 5: Repeat steps 3 and 4.\n",
        "\n",
        "Q5: At the start of the clustering exercise, discuss one method for determining the required number of\n",
        "clusters.\n",
        "\n",
        "ANS: Another clustering validation method would be to choose the optimal number of cluster by minimizing the within-cluster sum of squares (a measure of how tight each cluster is) and maximizing the between-cluster sum of squares (a measure of how seperated each cluster is from the others).\n",
        "\n",
        "Q6:Discuss the k-means algorithm&#39;s advantages and disadvantages.\n",
        "\n",
        "ANS: The main advantage of a clustered solution is automatic recovery from failure, that is, recovery without user intervention. Disadvantages of clustering are complexity and inability to recover from database corruption.\n",
        "\n",
        "Q7: Draw a diagram to demonstrate the principle of clustering.\n",
        "\n",
        "ANS: In machine learning too, we often group examples as a first step to understand a subject (data set) in a machine learning system. Grouping unlabeled examples is called clustering. As the examples are unlabeled, clustering relies on unsupervised machine learning.\n"
      ],
      "metadata": {
        "id": "z3AYovUDfUFK"
      }
    }
  ]
}