{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6sYuYNc7val"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shubham Kumar Chaturvedi(Machine_Learning assigment no: 9)"
      ],
      "metadata": {
        "id": "Iq4RRenb7z_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: What is feature engineering, and how does it work? Explain the various aspects of feature\n",
        "engineering in depth.\n",
        "\n",
        "ANS: Feature engineering in ML consists of four main steps: Feature Creation, Transformations, Feature Extraction, and Feature Selection. Feature engineering consists of creation, transformation, extraction, and selection of features, also known as variables, that are most conducive to creating an accurate ML algorithm.\n",
        "\n",
        "Q2: What is feature selection, and how does it work? What is the aim of it? What are the various\n",
        "methods of function selection?\n",
        "\n",
        "ANS: Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data. It is the process of automatically choosing relevant features for your machine learning model based on the type of problem you are trying to solve.\n",
        "\n",
        "Q3: Describe the function selection filter and wrapper approaches. State the pros and cons of each\n",
        "approach?\n",
        "\n",
        "ANS: Filter methods measure the relevance of features by their correlation with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it. Filter methods are much faster compared to wrapper methods as they do not involve training the models.\n",
        "\n",
        "Q4: i. Describe the overall feature selection process.\n",
        "\n",
        "ii. Explain the key underlying principle of feature extraction using an example. What are the most\n",
        "widely used function extraction algorithms?\n",
        "\n",
        "ANS: It can be used for feature selection by evaluating the Information gain of each variable in the context of the target variable.\n",
        "\n",
        "Chi-square Test. \n",
        "\n",
        "Fisher's Score. \n",
        "\n",
        "Correlation Coefficient. \n",
        "\n",
        "Dispersion ratio. \n",
        "\n",
        "Backward Feature Elimination. \n",
        "\n",
        "Recursive Feature Elimination. \n",
        "\n",
        "Random Forest Importance.\n",
        "\n",
        "Q5: Describe the feature engineering process in the sense of a text categorization issue.\n",
        "\n",
        "ANS: Feature engineering in NLP is understanding the context of the text.\n",
        "\n",
        "1.Count the number of characters present in a tweet.\n",
        "\n",
        "2.Count the number of words present in a tweet.\n",
        "\n",
        "3.Count the number of capital characters present in a tweet.\n",
        "\n",
        "4.Count the number of capital words present in a tweet.\n",
        "\n",
        "5.Count the number of punctuations.\n",
        "\n",
        "6.Number of words in quotes.\n",
        "\n",
        "7.Count the number of sentences in a tweet.\n",
        "\n",
        "8.Count the number of unique words in a tweet.\n",
        "\n",
        "9.we can count the number of times users used the hashtag.\n",
        "\n",
        "10.Counting the number of mentions can also be treated as a feature.\n",
        "\n",
        "11.we will count the number of stopwords used in a tweet.\n",
        "\n",
        "12.Calculating average word length.\n",
        "\n",
        "13.Calculating average sentence length.\n",
        "\n",
        "14.unique words vs word count feature.\n",
        "\n",
        "15.Stopwords count vs words counts feature.\n",
        "\n",
        "\n",
        "Q6: Make a few quick notes on:\n",
        "\n",
        "1. PCA is an acronym for Personal Computer Analysis.\n",
        "\n",
        "2. Use of vectors\n",
        "\n",
        "3. Embedded technique\n",
        "\n",
        "ANS: 1. Principal component analysis, or PCA, is a statistical procedure that allows you to summarize the information content in large data tables by means of a smaller set of “summary indices” that can be more easily visualized and analyzed.\n",
        "\n",
        "2.Most commonly in physics, vectors are used to represent displacement, velocity, and acceleration. Vectors are a combination of magnitude and direction and are drawn as arrows. The length represents the magnitude and the direction of that quantity is the direction in which the vector is pointing.\n",
        "\n",
        "3.Embedded methods combine the qualities' of filter and wrapper methods. It's implemented by algorithms that have their own built-in feature selection methods. Some of the most popular examples of these methods are LASSO and RIDGE regression which have inbuilt penalization functions to reduce overfitting.\n",
        "\n",
        "Q7: 10. Make a comparison between:\n",
        "\n",
        "1. Sequential backward exclusion vs. sequential forward selection.\n",
        "\n",
        "2. Function selection methods: filter vs. wrapper.\n",
        "\n",
        "3. SMC vs. Jaccard coefficient.\n",
        "\n",
        "\n",
        "ANS: 1. Sequential backward selection (SBS), in which features are sequentially removed from a full candidate set until the removal of further features increase the criterion.\n",
        "\n",
        "2.The main differences between the filter and wrapper methods for feature selection are: Filter methods measure the relevance of features by their correlation with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it.\n",
        "\n",
        "3.The SMC counts both mutual presences (when an attribute is present in both sets) and mutual absence (when an attribute is absent in both sets) as matches and compares it to the total number of attributes in the universe, whereas the Jaccard index only counts mutual presence as matches and compares it to the number of attributes that have been chosen by at least one of the two sets.\n"
      ],
      "metadata": {
        "id": "FBLN_ZnD75mq"
      }
    }
  ]
}