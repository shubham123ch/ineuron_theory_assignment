{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Shubham Kumar Chaturvedi(Machine_Learning assigment no: 24)"
      ],
      "metadata": {
        "id": "c9zt0u_rm5UA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: What is your definition of clustering? What are a few clustering algorithms you might think of?\n",
        "\n",
        "ANS: Grouping unlabeled examples is called clustering. As the examples are unlabeled, clustering relies on unsupervised machine learning. If the examples are labeled, then clustering becomes classification.\n",
        "\n",
        "Density-based,\n",
        "Distribution-based,\n",
        "Centroid-based,\n",
        "Hierarchical-based,\n",
        "K-means clustering algorithm,\n",
        "DBSCAN clustering algorithm,\n",
        "Gaussian Mixture Model algorithm,\n",
        "BIRCH algorithm.\n",
        "\n",
        "Q2: What are some of the most popular clustering algorithm applications?\n",
        "\n",
        "ANS: K-Means Algorithm. The most commonly used algorithm, K-means clustering, is a centroid-based algorithm.\n",
        "\n",
        "Mean-Shift Algorithm. \n",
        "\n",
        "DBSCAN Algorithm. \n",
        "\n",
        "Expectation-Maximization Clustering using Gaussian Mixture Models. \n",
        "\n",
        "Agglomerative Hierarchical Algorithm.\n",
        "\n",
        "Q3: When using K-Means, describe two strategies for selecting the appropriate number of clusters.\n",
        "\n",
        "ANS: The elbow method runs k-means clustering (kmeans number of clusters) on the dataset for a range of values of k (say 1 to 10). Perform K-means clustering with all these different values of K. For each of the K values, we calculate average distances to the centroid across all data points.\n",
        "\n",
        "Q4: Provide two examples of clustering algorithms that can handle large datasets. And two that look\n",
        "for high-density areas?\n",
        "\n",
        "ANS: CLARA (clustering large applications.) It is a sample-based method that randomly selects a small subset of data points instead of considering the whole observations, which means that it works well on a large dataset.\n",
        "\n",
        "The most popular and reasonable type is the agglomerative one, where you start by inputting the number of data points, that then are subsequently united into larger and larger clusters, until the limit is reached.\n",
        "\n",
        "Q5: Can you think of a scenario in which constructive learning will be advantageous? How can you go\n",
        "about putting it into action?\n",
        "\n",
        "ANS: The Constructivist process works best when children can compare and share their ideas with others. At home, this can be a parent, a sibling or even a playmate. Discussions with others can provide learners with the opportunities to express what they have learned and even correct mistakes that may take place.\n",
        "\n",
        "Q6: How do you tell the difference between anomaly and novelty detection?\n",
        "\n",
        "ANS: Novelty detection is when you have new data (i.e. OOD) and you want to know whether or not it is in-distribution. You want to know if it looks like the data you trained on. Anomaly detection is when you test your data to see if it is different than what you trained the model.\n",
        "\n",
        "Q7: What is a Gaussian mixture, and how does it work? What are some of the things you can do about\n",
        "it?\n",
        "\n",
        "ANS: A Gaussian Mixture is a function that is comprised of several Gaussians, each identified by k ∈ {1,…, K}, where K is the number of clusters of our dataset. Each Gaussian k in the mixture is comprised of the following parameters: A mean μ that defines its centre. A covariance Σ that defines its width.\n",
        "\n",
        "Q8: When using a Gaussian mixture model, can you name two techniques for determining the correct\n",
        "number of clusters?\n",
        "\n",
        "ANS: The two most popular evaluation metrics for picking cluster numbers for fitting Gaussian Mixture models are BIC and AIC. BIC stands for Bayesian information criterion and AIC stands for Akaike information criterion."
      ],
      "metadata": {
        "id": "sCfjMdM-nDdc"
      }
    }
  ]
}